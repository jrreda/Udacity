{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "461af88b-5e4d-486f-ba02-40d5543d6920",
   "metadata": {},
   "source": [
    "# A Simple Autoencoder\n",
    "\n",
    "We'll start off by building a simple autoencoder to compress the MNIST dataset. With autoencoders, we pass input data through an encoder that makes a compressed representation of the input. Then, this representation is passed through a decoder to reconstruct the input data. Generally the encoder and decoder will be built with neural networks, then trained on example data.\n",
    "\n",
    "<img src=\"autoencoder_1.png\" width=50%>\n",
    "\n",
    "In this notebook, we'll be build a simple network architecture for the encoder and decoder. Let's get started by importing our libraries and getting the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "332b9619-99a4-4bf0-bbc7-21a826215ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mahmo\\anaconda3\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import keras\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6968559-c346-4946-8c5d-557d657c7a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d499ec0-40ce-446c-82a8-42a871d1808a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2ad1d371460>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = x_train[2]\n",
    "plt.imshow(img.reshape((28, 28)), cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0beec105-774b-4787-b328-a7a87d639dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train/255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3db6d3-4263-499c-af53-8414844b5ceb",
   "metadata": {},
   "source": [
    "We'll train an autoencoder with these images by flattening them into 784 length vectors. The images from this dataset are already normalized such that the values are between 0 and 1. Let's start by building basically the simplest autoencoder with a **single ReLU** hidden layer. This layer will be used as the compressed representation. Then, the encoder is the input layer and the hidden layer. The decoder is the hidden layer and the output layer. Since the images are normalized between 0 and 1, we need to use a **sigmoid activation** on the output layer to get values matching the input.\n",
    "\n",
    "<img src=\"simple_autoencoder.png\" width=50%>\n",
    "\n",
    "\n",
    "**Exercise**: Build the graph for the autoencoder in the cell below. The input images will be flattened into 784 length vectors. The targets are the same as the inputs. And there should be one hidden layer with a ReLU activation and an output layer with a sigmoid activation. Feel free to use TensorFlow's higher level API, `tf.layers`. For instance, you would use `tf.layers.dense(inputs, units, activation=tf.nn.relu)` to create a fully connected layer with a ReLU activation. The loss should be calculated with the cross-entropy loss, there is a convenient TensorFlow function for this `tf.nn.sigmoid_cross_entropy_with_logits` ([documentation](https://www.tensorflow.org/api_docs/python/tf/nn/sigmoid_cross_entropy_with_logits)). You should note that `tf.nn.sigmoid_cross_entropy_with_logits` takes the logits, but to get the reconstructed images you'll need to pass the logits through the sigmoid function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "745fd386-a689-461b-9b22-c445a1eba172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2c3704a-d6e6-471f-b6b3-1fb161a4d17d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[2].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98969582-9319-4d71-9d13-8ba5c6c3c95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size of the encoding layer (the hidden layer)\n",
    "encoding_dim = 32 # feel free to change this value\n",
    "\n",
    "image_size = x_train[2].shape[1]    # 28\n",
    "\n",
    "# Input and target placeholders\n",
    "inputs_ = tf.placeholder(tf.float32, (None, image_size), name='inputs')\n",
    "targets_ = tf.placeholder(tf.float32, (None, image_size), name='targets')\n",
    "\n",
    "# Output of hidden layer, single fully connected layer here with ReLU activation\n",
    "encoded = tf.layers.dense(inputs_, encoding_dim, activation=tf.nn.relu)\n",
    "\n",
    "# Output layer logits, fully connected layer with no activation\n",
    "logits = tf.layers.dense(encoded, image_size, activation=None)\n",
    "# Sigmoid output from logits\n",
    "decoded = tf.nn.sigmoid(logits, name='output')\n",
    "\n",
    "# Sigmoid cross-entropy loss\n",
    "loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=targets_, logits=logits)\n",
    "# Mean of the loss\n",
    "cost = tf.reduce_mean(loss)\n",
    "\n",
    "# Adam optimizer\n",
    "opt = tf.train.AdamOptimizer(0.001).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5776e472-56aa-47a5-9c6f-1bf7432d2e44",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "540bee45-f657-45d1-91ae-288a57420523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the session\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b6c6bd-1629-4cc2-abc1-106207cabcca",
   "metadata": {},
   "source": [
    "Here I'll write a bit of code to train the network. I'm not too interested in validation here, so I'll just monitor the training loss.\n",
    "\n",
    "Calling `mnist.train.next_batch(batch_size)` will return a tuple of `(images, labels)`. We're not concerned with the labels here, we just need the images. Otherwise this is pretty straightfoward training with TensorFlow. We initialize the variables with `sess.run(tf.global_variables_initializer())`. Then, run the optimizer and get the loss with `batch_cost, _ = sess.run([cost, opt], feed_dict=feed)`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "44e7f70d-924d-44ac-bc47-8828e8fc4d9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8), 60000)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train), y_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bd5125ab-f66a-4c0c-b477-3bbea1e7c240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1971f8fc-901e-4a95-865d-1dcb0979ecab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "60000 / 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96481f62-c177-447f-8129-6f6acdb6adc6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mnist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7604/2876737125.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mii\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_examples\u001b[0m\u001b[1;33m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mfeed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0minputs_\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets_\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mnist' is not defined"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "batch_size = 200\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for e in range(epochs):\n",
    "    for ii in range(y_train.shape[0]//batch_size):\n",
    "        batch = mnist.train.next_batch(batch_size)\n",
    "        feed = {inputs_: batch[0], targets_: batch[0]}\n",
    "        batch_cost, _ = sess.run([cost, opt], feed_dict=feed)\n",
    "\n",
    "        print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "              \"Training loss: {:.4f}\".format(batch_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4b1c7af2-35a3-49fe-9a59-274a83aef0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sess.close()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
