{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to Spacy’s EntityRuler¶\n",
        "\n",
        "The Python library spaCy offers a few different methods for performing rules-based NER. One such method is via its EntityRuler.\n",
        "\n",
        "The EntityRuler is a spaCy factory that allows one to create a set of patterns with corresponding labels. A factory in spaCy is a set of classes and functions preloaded in spaCy that perform set tasks. In the case of the EntityRuler, the factory at hand allows the user to create an EntityRuler, give it a set of instructions, and then use this instructions to find and label entities.\n",
        "\n",
        "Once the user has created the EntityRuler and given it a set of instructions, the user can then add it to the spaCy pipeline as a new pipe. I have spoken in the past notebooks briefly about pipes, but perhaps it is good to address them in more detail here.\n",
        "\n",
        "A pipe is a component of a pipeline. A pipeline’s purpose is to take input data, perform some sort of operations on that input data, and then output those operations either as a new data or extracted metadata. A pipe is an individual component of a pipeline. In the case of spaCy, there are a few different pipes that perform different tasks. The tokenizer, tokenizes the text into individual tokens; the parser, parses the text, and the NER identifies entities and labels them accordingly. All of this data is stored in the Doc object as we saw in Notebook 01_01 of this series.\n",
        "\n",
        "It is important to remember that pipelines are sequential. This means that components earlier in a pipeline affect what later components receive. Sometimes this sequence is essential, meaning later pipes depend on earlier pipes. At other times, this sequence is not essential, meaning later pipes can function without earlier pipes. It is important to keep this in mind as you create custom spaCy models (or any pipeline for that matter).\n",
        "\n",
        "In this notebook, we will be looking closely at the EntityRuler as a component of a spaCy model’s pipeline. Off-the-shelf spaCy models come preloaded with an NER model; they do not, however, come with an EntityRuler. In order to incorperate an EntityRuler into a spaCy model, it must be created as a new pipe, given instructions, and then added to the model. Once this is complete, the user can save that new model with the EntityRuler to the disk.\n",
        "\n",
        "The full documentation of spaCy EntityRuler can be found here: https://spacy.io/api/entityruler .\n",
        "\n",
        "This notebook with synthesize this documentation for non-specialists and provide some examples of it in action."
      ],
      "metadata": {
        "id": "__zrbLd7tTv8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVdO9uaQkZVf",
        "outputId": "0233b51f-75c5-43c9-b17a-2c846f18be18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Treblinka GPE\n",
            "Poland GPE\n"
          ]
        }
      ],
      "source": [
        "#Import the requisite library\n",
        "import spacy\n",
        "\n",
        "#Build upon the spaCy Small Model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "#Sample text\n",
        "text = \"The village of Treblinka is in Poland. Treblinka was also an extermination camp.\"\n",
        "\n",
        "#Create the Doc object\n",
        "doc = nlp(text)\n",
        "\n",
        "#extract entities\n",
        "for ent in doc.ents:\n",
        "    print (ent.text, ent.label_)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The output from the code above demonstrates spaCy’s small model’s to identify Treblinka, which is a small village in Poland. As the sample text indicates, it was also an extermination camp during WWII. In the first sentence, the spaCy model tagged Treblinka as an LOC (location) and in the second it was missed entirely. Both are either imprecise or wrong. I would have accepted ORG for the second sentence, as spaCy’s model does not know how to classify an extermination camp, but what these results demonstrate is the model’s failure to generalize on data. The reason? There are a few, but I suspect the model never encountered the word Treblinka.\n",
        "\n",
        "This is a common problem in NLP for specific domains. Often times the domains in which we wish to deploy models, off-the-shelf models will fail because they have not been trained on domain-specific texts. We can resolve this, however, either via spaCy’s EntityRuler or via training a new model. As we will see over the next few notebooks, we can use spaCy’s EntityRuler to easily achieve both.\n",
        "\n",
        "For now, let’s first remedy the issue by giving the model instructions for correctly identifying Treblinka. For simplicity, we will use spaCy’s GPE label. In a later notebook, we will teach a model to correctly identify Treblinka in the latter context as a concentration camp."
      ],
      "metadata": {
        "id": "Wd1RVPb6uJ6b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Build upon the spaCy Small Model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "#Create the EntityRuler\n",
        "ruler = nlp.add_pipe(\"entity_ruler\")\n",
        "\n",
        "#List of Entities and Patterns\n",
        "patterns = [\n",
        "    {'label':'LOC', 'pattern':'Treblinka'}\n",
        "]\n",
        "ruler.add_patterns(patterns)\n",
        "\n",
        "#Create the Doc object\n",
        "doc = nlp(text)\n",
        "\n",
        "#extract entities\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.label_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDEfU1getDd-",
        "outputId": "d14a1468-883b-49ed-e618-43e028e053b2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Treblinka GPE\n",
            "Poland GPE\n",
            "Treblinka LOC\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.analyze_pipes()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CA0Sj70StHo8",
        "outputId": "29fabf54-7dd3-4ddb-ef57-e8220a6c90f9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'summary': {'tok2vec': {'assigns': ['doc.tensor'],\n",
              "   'requires': [],\n",
              "   'scores': [],\n",
              "   'retokenizes': False},\n",
              "  'tagger': {'assigns': ['token.tag'],\n",
              "   'requires': [],\n",
              "   'scores': ['tag_acc'],\n",
              "   'retokenizes': False},\n",
              "  'parser': {'assigns': ['token.dep',\n",
              "    'token.head',\n",
              "    'token.is_sent_start',\n",
              "    'doc.sents'],\n",
              "   'requires': [],\n",
              "   'scores': ['dep_uas',\n",
              "    'dep_las',\n",
              "    'dep_las_per_type',\n",
              "    'sents_p',\n",
              "    'sents_r',\n",
              "    'sents_f'],\n",
              "   'retokenizes': False},\n",
              "  'attribute_ruler': {'assigns': [],\n",
              "   'requires': [],\n",
              "   'scores': [],\n",
              "   'retokenizes': False},\n",
              "  'lemmatizer': {'assigns': ['token.lemma'],\n",
              "   'requires': [],\n",
              "   'scores': ['lemma_acc'],\n",
              "   'retokenizes': False},\n",
              "  'ner': {'assigns': ['doc.ents', 'token.ent_iob', 'token.ent_type'],\n",
              "   'requires': [],\n",
              "   'scores': ['ents_f', 'ents_p', 'ents_r', 'ents_per_type'],\n",
              "   'retokenizes': False},\n",
              "  'entity_ruler': {'assigns': ['doc.ents', 'token.ent_type', 'token.ent_iob'],\n",
              "   'requires': [],\n",
              "   'scores': ['ents_f', 'ents_p', 'ents_r', 'ents_per_type'],\n",
              "   'retokenizes': False}},\n",
              " 'problems': {'tok2vec': [],\n",
              "  'tagger': [],\n",
              "  'parser': [],\n",
              "  'attribute_ruler': [],\n",
              "  'lemmatizer': [],\n",
              "  'ner': [],\n",
              "  'entity_ruler': []},\n",
              " 'attrs': {'token.head': {'assigns': ['parser'], 'requires': []},\n",
              "  'token.tag': {'assigns': ['tagger'], 'requires': []},\n",
              "  'doc.tensor': {'assigns': ['tok2vec'], 'requires': []},\n",
              "  'token.is_sent_start': {'assigns': ['parser'], 'requires': []},\n",
              "  'doc.sents': {'assigns': ['parser'], 'requires': []},\n",
              "  'doc.ents': {'assigns': ['ner', 'entity_ruler'], 'requires': []},\n",
              "  'token.ent_type': {'assigns': ['ner', 'entity_ruler'], 'requires': []},\n",
              "  'token.dep': {'assigns': ['parser'], 'requires': []},\n",
              "  'token.lemma': {'assigns': ['lemmatizer'], 'requires': []},\n",
              "  'token.ent_iob': {'assigns': ['ner', 'entity_ruler'], 'requires': []}}}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This can be a bit difficult to read at first, but what it shows us is the order in which our pipes are set up and a few other key pieces of information about each pipe. If we locate “ner”, we notice that “entity_ruler” sits behind it.\n",
        "\n",
        "In order for our EntityRuler to have primacy, we have to assign it to before the “ner” pipe, as the example below shows in this line:\n",
        "\n",
        "`ruler = nlp.add_pipe(“entity_ruler”, before=”ner”)`"
      ],
      "metadata": {
        "id": "BqQGXuRkvk1r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Build upon the spaCy Small Model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "#Create the EntityRuler\n",
        "ruler = nlp.add_pipe(\"entity_ruler\", before='ner')\n",
        "\n",
        "#List of Entities and Patterns\n",
        "patterns = [\n",
        "    {'label':'LOC', 'pattern':'Treblinka'}\n",
        "]\n",
        "ruler.add_patterns(patterns)\n",
        "\n",
        "#Create the Doc object\n",
        "doc = nlp(text)\n",
        "\n",
        "#extract entities\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.label_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3x6R8tCRtHrZ",
        "outputId": "af7dcf7c-6bcd-438d-f80b-e424921f3e89"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Treblinka LOC\n",
            "Poland GPE\n",
            "Treblinka LOC\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introducing Complex Rules and Variance to the EntityRuler (Advanced)\n",
        "\n",
        "In some instances, labels may have a set type of variance that follow a distinct pattern or sets of patterns. One such example (included in the spaCy documentation) is phone numbers. In the United States, phone numbers have a few forms. The standard formal method is (xxx)-xxx-xxxx, but it is not uncommon to see xxx-xxx-xxxx or xxxxxxxxxx. If the owner of the phone number is giving that same number to someone outside the US, then +1(xxx)-xxx-xxxx.\n",
        "\n",
        "If you are working within a United States domain, you can pass RegEx formulas to the pattern matcher to grab all of these instances.\n",
        "\n",
        "The spaCy EntityRuler also allows the user to introduce a variety of complex rules and variances (via, among other things, RegEx) by passing the rules to the pattern. There are many arguments that one can pass to the patterns. For a complete list, see: https://spacy.io/usage/rule-based-matching . To expiremnet with how these work, I recommend using the spaCy Matcher demo: https://explosion.ai/demos/matcher ."
      ],
      "metadata": {
        "id": "q-8euOncwMjU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Sample text\n",
        "text = \"This is a sample number (555) 555-5555.\"\n",
        "\n",
        "#Build upon the spaCy Small Model\n",
        "nlp = spacy.blank(\"en\")\n",
        "\n",
        "# Create the Ruler and Add it\n",
        "ruler = nlp.add_pipe(\"entity_ruler\")\n",
        "\n",
        "#List of Entities and Patterns (source: https://spacy.io/usage/rule-based-matching)\n",
        "patterns = [\n",
        "    {'label': 'PHONE_NUMBER', 'pattern':[\n",
        "        {\"ORTH\": \"(\"},\n",
        "        {\"SHAPE\": \"ddd\"},\n",
        "        {\"ORTH\": \")\"},\n",
        "        {\"SHAPE\": \"ddd\"},\n",
        "        {\"ORTH\": \"-\", \"OP\": \"?\"},\n",
        "        {\"SHAPE\": \"dddd\"}\n",
        "    ]}\n",
        "]\n",
        "\n",
        "#add patterns to ruler\n",
        "ruler.add_patterns(patterns)\n",
        "\n",
        "#create the doc\n",
        "doc = nlp(text)\n",
        "\n",
        "#extract entities\n",
        "for ent in doc.ents:\n",
        "    print (ent.text, ent.label_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0pDI_eLtHuR",
        "outputId": "6aab65c1-828c-457b-9bf3-270249deb2d0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(555) 555-5555 PHONE_NUMBER\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1A1WAwGU06NC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%html\n",
        "<div align=\"center\">\n",
        "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/wpyCzodvO3A\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n",
        "</div>"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "pR_FtbkvoFj0",
        "outputId": "6a5ad027-3705-42a1-a13f-f1c27abbcf3a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div align=\"center\">\n",
              "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/wpyCzodvO3A\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n",
              "</div>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H-ouGxaVoIVl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}