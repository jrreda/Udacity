{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bpfa_rRj1BMr",
        "outputId": "e3ffc734-4724-417e-a9f1-1341a9a44ab4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n"
          ]
        }
      ],
      "source": [
        "import spacy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.matcher import Matcher"
      ],
      "metadata": {
        "id": "0Phj8egv1IqD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "matcher = Matcher(nlp.vocab)\n",
        "\n",
        "patterns = [{\"LIKE_EMAIL\": True}]\n",
        "matcher.add(\"EMAIL_ADDRESS\", [patterns])\n",
        "\n",
        "doc = nlp(\"This is an email address: wmattingly@aol.com\")\n",
        "matches = matcher(doc)\n",
        "\n",
        "matches"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M78cCjTB1MAT",
        "outputId": "a4b79f51-cbc0-4e72-9473-c256f37da41a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(16571425990740197027, 6, 7)]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lexeme, start token, end token\n",
        "nlp.vocab[matches[0][0]].text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1LdiHrq45EpE",
        "outputId": "b8f737c5-40bb-4ab9-bd63-972edbbd1e51"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'EMAIL_ADDRESS'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Attributes Taken by Matcher\n",
        "\n",
        "- ORTH - The exact verbatim of a token (str)\n",
        "- TEXT - The exact verbatim of a token (str)\n",
        "- LOWER - The lowercase form of the token text (str)\n",
        "- LENGTH - The length of the token text (int)\n",
        "- IS_ALPHA\n",
        "- IS_ASCII\n",
        "- IS_DIGIT\n",
        "- IS_LOWER\n",
        "- IS_UPPER\n",
        "- IS_TITLE\n",
        "- IS_PUNCT\n",
        "- IS_SPACE\n",
        "- IS_STOP\n",
        "- IS_SENT_START\n",
        "- LIKE_NUM\n",
        "- LIKE_URL\n",
        "- LIKE_EMAIL\n",
        "- SPACY\n",
        "- POS\n",
        "- TAG\n",
        "- MORPH\n",
        "- DEP\n",
        "- LEMMA\n",
        "- SHAPE\n",
        "- ENT_TYPE\n",
        "- _ - Custom extension attributes (Dict[str, Any])\n",
        "- OP\n"
      ],
      "metadata": {
        "id": "LfAXsDpo5gfv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Applied Matcher\n"
      ],
      "metadata": {
        "id": "A2f18HRb9Ir2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open (\"wiki_mlk.txt\", \"r\") as f:\n",
        "    text = f.read()\n",
        "\n",
        "text[:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "deCURpAM85io",
        "outputId": "a842de03-8f1d-41a0-fc52-9cb40e24163c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Martin Luther King Jr. (born Michael King Jr.; January 15, 1929 â€“ April 4, 1968) was an American Bap'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Grabbing all Proper Nouns"
      ],
      "metadata": {
        "id": "qWGyjK4E9PU_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "matcher = Matcher(nlp.vocab)\n",
        "patterns = [{'POS':'PROPN'}]\n",
        "matcher.add(\"PROPER_NOUNS\", [patterns])\n",
        "\n",
        "doc = nlp(text)\n",
        "matches = matcher(doc)\n",
        "print(len(matches))\n",
        "for match in matches[:10]:\n",
        "    print(match, doc[match[1]:match[2]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Jmg8WzI9Lmw",
        "outputId": "ee51de69-ace8-4da8-fb3f-07932301e820"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "103\n",
            "(3232560085755078826, 0, 1) Martin\n",
            "(3232560085755078826, 1, 2) Luther\n",
            "(3232560085755078826, 2, 3) King\n",
            "(3232560085755078826, 3, 4) Jr.\n",
            "(3232560085755078826, 6, 7) Michael\n",
            "(3232560085755078826, 7, 8) King\n",
            "(3232560085755078826, 8, 9) Jr.\n",
            "(3232560085755078826, 10, 11) January\n",
            "(3232560085755078826, 15, 16) April\n",
            "(3232560085755078826, 49, 50) King\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Improving it with Multi-Word Tokens"
      ],
      "metadata": {
        "id": "aaLzAiWq93d8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "matcher = Matcher(nlp.vocab)\n",
        "patterns = [{'POS':'PROPN', 'OP':'+'}]\n",
        "matcher.add(\"PROPER_NOUNS\", [patterns])\n",
        "\n",
        "doc = nlp(text)\n",
        "matches = matcher(doc)\n",
        "print(len(matches))\n",
        "for match in matches[:10]:\n",
        "    print(match, doc[match[1]:match[2]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_A0TvQs902B",
        "outputId": "d1081fe4-d1ad-4aea-c4c2-ffe55fa6b1d6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "176\n",
            "(3232560085755078826, 0, 1) Martin\n",
            "(3232560085755078826, 0, 2) Martin Luther\n",
            "(3232560085755078826, 1, 2) Luther\n",
            "(3232560085755078826, 0, 3) Martin Luther King\n",
            "(3232560085755078826, 1, 3) Luther King\n",
            "(3232560085755078826, 2, 3) King\n",
            "(3232560085755078826, 0, 4) Martin Luther King Jr.\n",
            "(3232560085755078826, 1, 4) Luther King Jr.\n",
            "(3232560085755078826, 2, 4) King Jr.\n",
            "(3232560085755078826, 3, 4) Jr.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Greedy Keyword Argument"
      ],
      "metadata": {
        "id": "675KzXgD-Dvm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "matcher = Matcher(nlp.vocab)\n",
        "patterns = [{'POS':'PROPN', 'OP':'+'}]\n",
        "matcher.add(\"PROPER_NOUNS\", [patterns], greedy='LONGEST')\n",
        "\n",
        "doc = nlp(text)\n",
        "matches = matcher(doc)\n",
        "print(len(matches))\n",
        "for match in matches[:10]:\n",
        "    print(match, doc[match[1]:match[2]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4eOg2wT-Dio",
        "outputId": "a7dbc672-d8f0-4e11-f71d-048d1732ef80"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "62\n",
            "(3232560085755078826, 83, 88) Martin Luther King Sr.\n",
            "(3232560085755078826, 469, 474) Martin Luther King Jr. Day\n",
            "(3232560085755078826, 536, 541) Martin Luther King Jr. Memorial\n",
            "(3232560085755078826, 0, 4) Martin Luther King Jr.\n",
            "(3232560085755078826, 128, 132) Southern Christian Leadership Conference\n",
            "(3232560085755078826, 247, 251) Director J. Edgar Hoover\n",
            "(3232560085755078826, 6, 9) Michael King Jr.\n",
            "(3232560085755078826, 325, 328) Nobel Peace Prize\n",
            "(3232560085755078826, 422, 425) James Earl Ray\n",
            "(3232560085755078826, 463, 466) Congressional Gold Medal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sorting it to Apperance"
      ],
      "metadata": {
        "id": "ZzcHzwv0-MWi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "matcher = Matcher(nlp.vocab)\n",
        "patterns = [{'POS':'PROPN', 'OP':'+'}]\n",
        "matcher.add(\"PROPER_NOUNS\", [patterns], greedy='LONGEST')\n",
        "\n",
        "doc = nlp(text)\n",
        "matches = matcher(doc)\n",
        "matches.sort(key=lambda x: x[1])\n",
        "print(len(matches))\n",
        "for match in matches[:10]:\n",
        "    print(match, doc[match[1]:match[2]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LZifWd3-AHE",
        "outputId": "a5e36de6-2d22-49da-ce2c-d4cfaaae565a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "62\n",
            "(3232560085755078826, 0, 4) Martin Luther King Jr.\n",
            "(3232560085755078826, 6, 9) Michael King Jr.\n",
            "(3232560085755078826, 10, 11) January\n",
            "(3232560085755078826, 15, 16) April\n",
            "(3232560085755078826, 49, 50) King\n",
            "(3232560085755078826, 69, 71) Mahatma Gandhi\n",
            "(3232560085755078826, 83, 88) Martin Luther King Sr.\n",
            "(3232560085755078826, 89, 90) King\n",
            "(3232560085755078826, 113, 114) King\n",
            "(3232560085755078826, 117, 118) Montgomery\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adding in Sequences"
      ],
      "metadata": {
        "id": "UNXukKm2-atV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "matcher = Matcher(nlp.vocab)\n",
        "patterns = [{'POS':'PROPN', 'OP':'+'},\n",
        "            {'POS':'VERB'}]\n",
        "matcher.add(\"PROPER_NOUNS\", [patterns], greedy='LONGEST')\n",
        "\n",
        "doc = nlp(text)\n",
        "matches = matcher(doc)\n",
        "matches.sort(key=lambda x: x[1])\n",
        "print(len(matches))\n",
        "for match in matches[:10]:\n",
        "    print(match, doc[match[1]:match[2]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Zx9Apob-Wsj",
        "outputId": "02fe53ec-d717-466f-cdc8-ef86d7d2d314"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n",
            "(3232560085755078826, 49, 51) King advanced\n",
            "(3232560085755078826, 89, 91) King participated\n",
            "(3232560085755078826, 113, 115) King led\n",
            "(3232560085755078826, 167, 169) King helped\n",
            "(3232560085755078826, 198, 200) SCLC put\n",
            "(3232560085755078826, 247, 252) Director J. Edgar Hoover considered\n",
            "(3232560085755078826, 322, 324) King won\n",
            "(3232560085755078826, 485, 488) United States beginning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finding Quotes and Speakers"
      ],
      "metadata": {
        "id": "oXrBuBB--kpN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open (\"alice.json\", \"r\") as f:\n",
        "    data = json.load(f)"
      ],
      "metadata": {
        "id": "qpl2FrY3-hlw"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = data[0][2][0]\n",
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "-yb4qTbp_Dei",
        "outputId": "f9f98351-781d-4af3-96b5-bde359fa9bf6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Alice was beginning to get very tired of sitting by her sister on the bank, and of having nothing to do: once or twice she had peeped into the book her sister was reading, but it had no pictures or conversations in it, `and what is the use of a book,' thought Alice `without pictures or conversation?'\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = data[0][2][0].replace( \"`\", \"'\")\n",
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "Wei9Toof_OV8",
        "outputId": "75d2a8c4-6257-4fbe-db26-95bd936b73b4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Alice was beginning to get very tired of sitting by her sister on the bank, and of having nothing to do: once or twice she had peeped into the book her sister was reading, but it had no pictures or conversations in it, 'and what is the use of a book,' thought Alice 'without pictures or conversation?'\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "matcher = Matcher(nlp.vocab)\n",
        "patterns = [{'ORTH':\"'\"},\n",
        "            {'IS_ALPHA':True, 'OP':'+'},\n",
        "            {'IS_PUNCT':True, 'OP':'*'},\n",
        "            {'ORTH':\"'\"}\n",
        "            ]\n",
        "matcher.add(\"PROPER_NOUNS\", [patterns], greedy='LONGEST')\n",
        "\n",
        "doc = nlp(text)\n",
        "matches = matcher(doc)\n",
        "matches.sort(key=lambda x:x[1])\n",
        "print(len(matches))\n",
        "for match in matches[:10]:\n",
        "    print(match, doc[match[1]:match[2]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7KdB_cP_RkB",
        "outputId": "34c17b64-9019-4e57-d190-9c6ba39272d3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "(3232560085755078826, 47, 58) 'and what is the use of a book,'\n",
            "(3232560085755078826, 60, 67) 'without pictures or conversation?'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Find Speaker"
      ],
      "metadata": {
        "id": "knG214KjAPN3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "speak_lemmas = ['think', 'say']\n",
        "text = data[0][2][0].replace( \"`\", \"'\")\n",
        "\n",
        "matcher = Matcher(nlp.vocab)\n",
        "patterns_1 = [{'ORTH': \"'\"},\n",
        "              {'IS_ALPHA': True, \"OP\": \"+\"},\n",
        "              {'IS_PUNCT': True, \"OP\": \"*\"},\n",
        "\n",
        "              {'ORTH': \"'\"},\n",
        "              {\"POS\": \"VERB\", \"LEMMA\": {\"IN\": speak_lemmas}},\n",
        "              {\"POS\": \"PROPN\", \"OP\": \"+\"},\n",
        "              {'ORTH': \"'\"},\n",
        "\n",
        "              {'IS_ALPHA': True, \"OP\": \"+\"},\n",
        "              {'IS_PUNCT': True, \"OP\": \"*\"},\n",
        "              {'ORTH': \"'\"}]\n",
        "matcher.add(\"PROPER_NOUNS\", [patterns_1], greedy='LONGEST')\n",
        "\n",
        "doc = nlp(text)\n",
        "matches = matcher(doc)\n",
        "matches.sort(key=lambda x:x[1])\n",
        "print(len(matches))\n",
        "for match in matches[:10]:\n",
        "    print(match, doc[match[1]:match[2]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3Ba-6OfAIuR",
        "outputId": "ff49c797-4521-44c3-f9bb-aa5a5dd110aa"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "(3232560085755078826, 47, 67) 'and what is the use of a book,' thought Alice 'without pictures or conversation?'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for text in data[0][2]:\n",
        "    text = text.replace(\"`\", \"'\")\n",
        "    doc = nlp(text)\n",
        "    matches = matcher(doc)\n",
        "    matches.sort(key = lambda x: x[1])\n",
        "    print (len(matches))\n",
        "    for match in matches[:10]:\n",
        "        print (match, doc[match[1]:match[2]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lV_mke2VA7Dg",
        "outputId": "be44c6ea-a0c0-4eae-cd8d-595cc8763a06"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "(3232560085755078826, 47, 67) 'and what is the use of a book,' thought Alice 'without pictures or conversation?'\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adding More PatternsÂ¶"
      ],
      "metadata": {
        "id": "OvdU852dBKdG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "speak_lemmas = [\"think\", \"say\"]\n",
        "text = data[0][2][0].replace( \"`\", \"'\")\n",
        "matcher = Matcher(nlp.vocab)\n",
        "pattern1 = [{'ORTH': \"'\"}, {'IS_ALPHA': True, \"OP\": \"+\"}, {'IS_PUNCT': True, \"OP\": \"*\"}, {'ORTH': \"'\"},\n",
        "            {\"POS\": \"VERB\", \"LEMMA\": {\"IN\": speak_lemmas}},\n",
        "            {\"POS\": \"PROPN\", \"OP\": \"+\"}, {'ORTH': \"'\"}, {'IS_ALPHA': True, \"OP\": \"+\"},\n",
        "            {'IS_PUNCT': True, \"OP\": \"*\"}, {'ORTH': \"'\"}]\n",
        "pattern2 = [{'ORTH': \"'\"}, {'IS_ALPHA': True, \"OP\": \"+\"}, {'IS_PUNCT': True, \"OP\": \"*\"},\n",
        "            {'ORTH': \"'\"}, {\"POS\": \"VERB\", \"LEMMA\": {\"IN\": speak_lemmas}},\n",
        "            {\"POS\": \"PROPN\", \"OP\": \"+\"}]\n",
        "pattern3 = [{\"POS\": \"PROPN\", \"OP\": \"+\"},{\"POS\": \"VERB\", \"LEMMA\": {\"IN\": speak_lemmas}},\n",
        "            {'ORTH': \"'\"}, {'IS_ALPHA': True, \"OP\": \"+\"}, {'IS_PUNCT': True, \"OP\": \"*\"}, {'ORTH': \"'\"}]\n",
        "matcher.add(\"PROPER_NOUNS\", [pattern1, pattern2, pattern3], greedy='LONGEST')\n",
        "\n",
        "for text in data[0][2]:\n",
        "    text = text.replace(\"`\", \"'\")\n",
        "    doc = nlp(text)\n",
        "    matches = matcher(doc)\n",
        "    matches.sort(key = lambda x: x[1])\n",
        "    print (len(matches))\n",
        "    for match in matches[:10]:\n",
        "        print (match, doc[match[1]:match[2]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYQX6fcQBMNa",
        "outputId": "ea4e9efc-c1b3-4288-bbae-a2120793c923"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "(3232560085755078826, 47, 67) 'and what is the use of a book,' thought Alice 'without pictures or conversation?'\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "(3232560085755078826, 0, 6) 'Well!' thought Alice\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "(3232560085755078826, 57, 68) 'which certainly was not here before,' said Alice\n",
            "0\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TkdNrQ0aBUtV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}